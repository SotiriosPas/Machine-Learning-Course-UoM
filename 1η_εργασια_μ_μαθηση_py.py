# -*- coding: utf-8 -*-
"""1Î· Î•Î¡Î“Î‘Î£Î™Î‘ Îœ. ÎœÎ‘Î˜Î—Î£Î—.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1nbjvzI1vpK6s4eBp7JEpEkzklvvFSbyE

1o Î¼Î­ÏÎ¿Ï‚: Ï€ÏÎ¿ÏƒÎ­Î³Î³Î¹ÏƒÎ· ÎºÎ±Ï„Î¬ÏƒÏ„Î±ÏƒÎ·Ï‚ Ï…Ï€Î¿Î¸Î­Ï„Î¿Î½Ï„Î±Ï‚ Î¸ÏŒÏÏ…Î²Î¿ ÏƒÏ„Î¹Ï‚ Î¼ÎµÏ„ÏÎ®ÏƒÎµÎ¹Ï‚ ÎºÎ±Î¹ Î³Î½ÏÏƒÎ· Ï„Î¿Ï…
Ï€Î±ÏÎ±Î¼ÎµÏ„ÏÎ¹ÎºÎ¿Ï Î¼Î¿Î½Ï„Î­Î»Î¿Ï…

(Î³Î½ÏÏƒÎ· Î¼Î¿ÏÏ†Î®Ï‚ ÎµÎ¾Î¯ÏƒÏ‰ÏƒÎ·Ï‚, Î¬Î³Î½Ï‰ÏƒÏ„ÎµÏ‚ Î¿Î¹ Ï„Î¹Î¼Î­Ï‚ Ï„Ï‰Î½ ÏƒÏ…Î½Ï„ÎµÎ»ÎµÏƒÏ„ÏÎ½ ÏƒÏ„Î¿Ï…Ï‚ ÏŒÏÎ¿Ï…Ï‚).

1. Î˜Î± Î´Î·Î¼Î¹Î¿Ï…ÏÎ³Î®ÏƒÎµÏ„Îµ 150 Ï„Ï…Ï‡Î±Î¯Î¿Ï…Ï‚ Ï€ÏÎ±Î³Î¼Î±Ï„Î¹ÎºÎ¿ÏÏ‚ Î±ÏÎ¹Î¸Î¼Î¿ÏÏ‚ Ï€Î¿Ï… Î±ÎºÎ¿Î»Î¿Ï…Î¸Î¿ÏÎ½ Î¿Î¼Î¿Î¹ÏŒÎ¼Î¿ÏÏ†Î·
ÎºÎ±Ï„Î±Î½Î¿Î¼Î®. Î¦ÏÎ¿Î½Ï„Î¯ÏƒÏ„Îµ ÏÏƒÏ„Îµ Î· Î´Î¹Î¬Ï„Î±Î¾Î· Î¼Îµ Ï„Î¿Ï…Ï‚ Î±ÏÎ¹Î¸Î¼Î¿ÏÏ‚ Î½Î± Î²ÏÎ¯ÏƒÎºÎµÏ„Î±Î¹ ÏƒÎµ Î±ÏÎ¾Î¿Ï…ÏƒÎ± ÏƒÎµÎ¹ÏÎ¬.
ÎŒÎ»Î¿Î¹ Î¿Î¹ Î±ÏÎ¹Î¸Î¼Î¿Î¯ Ï€ÏÎ­Ï€ÎµÎ¹ Î½Î± Î±Î½Î®ÎºÎ¿Ï…Î½ ÏƒÏ„Î¿ Î´Î¹Î¬ÏƒÏ„Î·Î¼Î± [-4, 4].
"""

import numpy as np
import matplotlib.pyplot as plt
import scipy.optimize as opt

#ÎŸÏÎ¹ÏƒÎ¼ÏŒÏ‚ Ï„Î¿Ï… seed Ï€Î±ÏÎ±Î³Ï‰Î³Î®Ï‚ Ï„Ï…Ï‡Î±Î¯Ï‰Î½ Î±ÏÎ¹Î¸Î¼ÏÎ½.
run_with_seed = 6542468 #np.random.randint(0, 4294967295)
np.random.seed(run_with_seed)

#Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± Ï„Ï…Ï‡Î±Î¯Î±Ï‚ Î»Î¯ÏƒÏ„Î±Ï‚ Î¼Îµ Î¿Î¼Î¿Î¹ÏŒÎ¼Î¿ÏÏ†Î· ÎºÎ±Ï„Î±Î½Î¿Î¼Î® ÎºÎ±Î¹ Ï„Î±Î¾Î¹Î½ÏŒÎ¼Î·ÏƒÎ· Ï„Ï‰Î½ ÏƒÏ„Î¿Î¹Ï‡ÎµÎ¯Ï‰Î½ Ï„Î·Ï‚ ÏƒÎµ Î±ÏÎ¾Î¿Ï…ÏƒÎ± ÏƒÎµÎ¹ÏÎ¬.
randomNumList = np.random.uniform(-4, 4, 150)
sortedList = randomNumList
sortedList.sort()

"""2. Î˜Î± Î¿ÏÎ¯ÏƒÎµÏ„Îµ Ï„Î·Î½ Î±ÎºÏŒÎ»Î¿Ï…Î¸Î· ÏƒÏ…Î½Î¬ÏÏ„Î·ÏƒÎ· (function): ğ‘¦ = (ğœ†1) x (1/exp(ğ‘¥)) + (ğœ†2) x sin(ğ‘¥), Î¼Îµ ÏŒÎ½Î¿Î¼Î±
ÏƒÏ…Î½Î¬ÏÏ„Î·ÏƒÎ·Ï‚ myCustFunc().
H ÏƒÏ…Î½Î¬ÏÏ„Î·ÏƒÎ· myCustFunc(x, Î»1, Î»2 ) Ï€ÏÎ­Ï€ÎµÎ¹ Î½Î± Î´Î­Ï‡ÎµÏ„Î±Î¹ ÏƒÎ±Î½ ÏŒÏÎ¹ÏƒÎ¼Î± Î¼Î¹Î± Î´Î¹Î¬Ï„Î±Î¾Î· Î±ÏÎ¹Î¸Î¼ÏÎ½ ÏƒÎ±Î½
ÎºÎ±Î¹ Î±Ï…Ï„Î® Ï„Î¿Ï… ÎµÏÏ‰Ï„Î®Î¼Î±Ï„Î¿Ï‚ 1 ÎºÎ±Î¹ Ï„Î¹Ï‚ Ï„Î¹Î¼Î­Ï‚ Î³Î¹Î± Ï„Î¹Ï‚ Ï€Î±ÏÎ±Î¼Î­Ï„ÏÎ¿Ï…Ï‚ Î»1 ÎºÎ±Î¹ Î»2. Î˜Î± ÎµÏ€Î¹ÏƒÏ„ÏÎ­Ï†ÎµÎ¹ Î¼Î¹Î±
Î´Î¹Î¬Ï„Î±Î¾Î·(array) Î¯Î´Î¹Î¿Ï… Î¼ÎµÎ³Î­Î¸Î¿Ï…Ï‚ Î¼Îµ Î±Ï…Ï„Î® ÏƒÏ„Î·Î½ ÎµÎ¯ÏƒÎ¿Î´Î¿.
"""

#ÎŸÏÎ¹ÏƒÎ¼ÏŒÏ‚ Ï„Î·Ï‚ ÏƒÏ…Î½Î¬ÏÏ„Î·ÏƒÎ·Ï‚ myCustFunc, Î· Î¿Ï€Î¿Î¯Î± ÎµÏ€Î¹ÏƒÏ„ÏÎ­Ï†ÎµÎ¹ Î´Î¹Î¬Ï„Î±Î¾Î· Î¯Î´Î¹Î¿Ï… Î¼ÎµÎ³Î­Î¸Î¿Ï…Ï‚ Î¼Îµ Ï„Î·Î½ myArray.
def myCustFunc(myArray, l1, l2):
  newArray = (l1 * (1/(np.exp(myArray))) + l2 * (np.sin(myArray)))
  return newArray

"""3. Î˜Î± Î´Î·Î¼Î¹Î¿Ï…ÏÎ³Î®ÏƒÎµÏ„Îµ Î­Î½Î± (1) Î½Î­Î¿ array Î¼ÎµÎ³Î­Î¸Î¿Ï…Ï‚ 150 x 1, Î´Î¯Î½Î¿Î½Ï„Î±Ï‚ Ï„Î¹Î¼Î­Ï‚ Î³Î¹Î± Ï„Î± Î»1, Î»2 ÎºÎ±Î¹ Ï„Î¿
Î´Î¹Î¬Î½Ï…ÏƒÎ¼Î± x Ï€Î¿Ï… Ï€ÏÎ¿Î­ÎºÏ…ÏˆÎµ Î±Ï€ÏŒ Ï„Î¿ ÎµÏÏÏ„Î·Î¼Î± 1.
"""

#Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± Î»Î¯ÏƒÏ„Î±Ï‚ Î¼ÎµÎ³Î­Î¸Î¿Ï…Ï‚ 150 x 1, Î¼Îµ Ï€Î±ÏÎ±Î¼Î­Ï„ÏÎ¿Ï…Ï‚ Ï„Î·Î½ Ï„Î±Î¾Î¹Î½Î¿Î¼Î·Î¼Î­Î½Î· Î»Î¯ÏƒÏ„Î± Ï„Î¿Ï… ÎµÏÏ‰Ï„Î®Î¼Î±Ï„Î¿Ï‚ 1 ÎºÎ±Î¹ Î¼Îµ Ï„Ï…Ï‡Î±Î¯ÎµÏ‚ Ï„Î¹Î¼Î­Ï‚ Î»1 = 2 ÎºÎ±Î¹ Î»2 = 3.
customProcessedList = myCustFunc(sortedList, 2, 3)
#customProcessedList = myCustFunc(sortedList100elements, 2, 3)

"""4. Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î®ÏƒÏ„Îµ Î¼Î¯Î± Î³ÏÎ±Ï†Î¹ÎºÎ® Ï€Î±ÏÎ¬ÏƒÏ„Î±ÏƒÎ· ÏƒÏ„Î·Î½ Î¿Ï€Î¿Î¯Î± Î¸Î± Ï†Î±Î¯Î½Î¿Î½Ï„Î±Î¹ Ï„Î± Î´ÎµÎ´Î¿Î¼Î­Î½Î± Ï€Î¿Ï…
Î´Î·Î¼Î¹Î¿Ï…ÏÎ³Î®ÏƒÎ±Ï„Îµ ÏƒÏ„Î± ÎµÏÏ‰Ï„Î®Î¼Î±Ï„Î± 1 ÎºÎ±Î¹ 3. Î¤Î± outputs Ï„Ï‰Î½ ÏƒÏ…Î½Î±ÏÏ„Î®ÏƒÎµÏ‰Î½ Ï€ÏÎ­Ï€ÎµÎ¹ Î½Î±
Î´Î¹Î±Ï†Î¿ÏÎ¿Ï€Î¿Î¹Î¿ÏÎ½Ï„Î±Î¹: Ï‡ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹Î®ÏƒÏ„Îµ Î´Î¹Î±Ï†Î¿ÏÎµÏ„Î¹ÎºÎ¬ Ï‡ÏÏÎ¼Î±Ï„Î± ÎºÎ±Î¹ ÏƒÏÎ¼Î²Î¿Î»Î±. ÎœÎ·Î½ Î¾ÎµÏ‡Î¬ÏƒÎµÏ„Îµ Î½Î±
Î²Î¬Î»ÎµÏ„Îµ Ï„Î¯Ï„Î»Î¿, Î¿Î½ÏŒÎ¼Î±Ï„Î± Î±Î¾ÏŒÎ½Ï‰Î½, ÎºÎ±Î¹ Î»ÎµÎ¶Î¬Î½Ï„Î±, Î³Î¹Î± Î½Î± Î¾Î­ÏÎ¿Ï…Î¼Îµ Ï€Î¿Î¹Î± ÏƒÏ…Î½Î¬ÏÏ„Î·ÏƒÎ· Î´Î·Î¼Î¹Î¿ÏÏÎ³Î·ÏƒÎµ
Ï„Î± ÎµÎºÎ¬ÏƒÏ„Î¿Ï„Îµ Î´ÎµÎ´Î¿Î¼Î­Î½Î±.
"""

#Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± ÎµÎ½ÏŒÏ‚ Î³ÏÎ±Ï†Î®Î¼Î±Ï„Î¿Ï‚ Ï€Î¿Ï… Î±Ï€Î¿Ï„ÎµÎ»ÎµÎ¯Ï„Î±Î¹ Î±Ï€Î¿ Î´ÏÎ¿ Ï…Ï€Î¿Î³ÏÎ±Ï†Î®Î¼Î±Ï„Î±.
fig, (subp1, subp2) = plt.subplots(2)
fig.tight_layout(pad = 2.5)

#ÎšÎ±Ï„Î±Ï‡ÏÏÎ·ÏƒÎ· ÏƒÏ„Î¿Î¹Ï‡ÎµÎ¯Ï‰Î½ ÏƒÏ„Î¿ Ï€ÏÏÏ„Î¿ Ï…Ï€Î¿Î³ÏÎ¬Ï†Î·Î¼Î± Ï€Î¿Ï… Ï€Î±ÏÎ¿Ï…ÏƒÎ¹Î¬Î¶ÎµÎ¹ Ï„Î·Î½ Ï„Î±Î¾Î¹Î½Î¿Î¼Î·Î¼Î­Î½Î· Î»Î¯ÏƒÏ„Î± Î¼Îµ Ï„Î¿Ï…Ï‚ Ï„Ï…Ï‡Î±Î¯Î¿Ï…Ï‚ Î±ÏÎ¹Î¸Î¼Î¿ÏÏ‚.
x1 = sortedList
subp1.plot(x1, 'b-', label = "Uniform(), sort()")
subp1.legend()
subp1.set_ylabel('Values')
subp1.set_xlabel('Indices')
subp1.set_title('Randomly Generated and Sorted List')

#ÎšÎ±Ï„Î±Ï‡ÏÏÎ·ÏƒÎ· ÏƒÏ„Î¿Î¹Ï‡ÎµÎ¯Ï‰Î½ ÏƒÏ„Î¿ Î´ÎµÏÏ„ÎµÏÎ¿ Ï…Ï€Î¿Î³ÏÎ¬Ï†Î·Î¼Î± Ï€Î¿Ï… Ï€Î±ÏÎ¿Ï…ÏƒÎ¹Î¬Î¶ÎµÎ¹ Ï„Î·Î½ Î»Î¯ÏƒÏ„Î± Î¼Îµ Ï„Î¿Ï…Ï‚ Î±ÏÎ¹Î¸Î¼Î¿ÏÏ‚ Ï€Î¿Ï… Ï€ÏÎ¿Î­ÎºÏ…ÏˆÎ±Î½ Î±Ï€Î¿ Ï„Î·Î½ ÏƒÏ…Î½Î¬ÏÏ„Î·ÏƒÎ· myCustFunc.
x2 = customProcessedList
subp2.plot(x2, 'r-', label = "myCustFunc()")
subp2.legend()
subp2.set_ylabel('Values')
subp2.set_xlabel('Indices')
subp2.set_title("Custom Function's processed List")
plt.show()

"""5. Î•Î¹ÏƒÎ¬Î³ÎµÏ„Îµ Î¸ÏŒÏÏ…Î²Î¿ ÏƒÏ„Î± Î´ÎµÎ´Î¿Î¼Î­Î½Î± ÎµÎ¹ÏƒÏŒÎ´Î¿Ï… Ï€Î¿Ï… Î½Î± Î±ÎºÎ¿Î»Î¿Ï…Î¸ÎµÎ¯ Î¼Î¹Î± ÎºÎ±Ï„Î±Î½Î¿Î¼Î® Ï„Î·Ï‚ ÎµÏ€Î¹Î»Î¿Î³Î®Ï‚ ÏƒÎ±Ï‚
[*ÎµÎºÏ„ÏŒÏ‚* Ï„Î·Ï‚ ğ›®(0,1)]. Î ÎµÏÎ¹Î³ÏÎ¬ÏˆÏ„Îµ Ï„Î·Î½ ÎºÎ±Ï„Î±Î½Î¿Î¼Î® Ï€Î¿Ï… ÎµÏ€Î¹Î»Î­Î¾Î±Ï„Îµ, ÏƒÏ„Î·Î½ Î±Î½Î±Ï†Î¿ÏÎ¬ Ï€Î¿Ï… Î¸Î±
Ï…Ï€Î¿Î²Î¬Î»ÎµÏ„Îµ.
"""

#Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± Î»Î¯ÏƒÏ„Î±Ï‚ Î¼Îµ Ï„Ï…Ï‡Î±Î¯Î¿Ï…Ï‚ Î±ÏÎ¹Î¸Î¼Î¿ÏÏ‚ Ï‡ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹ÏÎ½Ï„Î±Ï‚ Ï„Î·Î½ ÎºÎ±Ï„Î±Î½Î¿Î¼Î® Laplace ÎºÎ±Î¹ Ï€ÏÎ¿ÏƒÎ¸Î®ÎºÎ· Î±Ï…Ï„ÏÎ½ ÏƒÏ„Î± Î±Ï€Î¿Ï„ÎµÎ»Î­ÏƒÎ¼Î±Ï„Î± Ï„Î·Ï‚ myCustFunc.
#Î§ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹Î¿ÏÎ½Ï„Î±Î¹ Î¿Î¹ default Ï„Î¹Î¼Î­Ï‚ Ï„Î·Ï‚ ÏƒÏ…Î½Î±ÏÏ„Î®ÏƒÎµÏ‰Ï‚ numpy.random.laplace(loc=0.0, scale=1.0, mySize).
laplaceNoise = np.random.laplace(0, 1, 150)
customNoisyList = customProcessedList + laplaceNoise

"""6. Î˜Î± ÎºÎ¬Î½ÎµÏ„Îµ fit Ï„Î¹Ï‚ Ï€Î±ÏÎ±Î¼Î­Ï„ÏÎ¿Ï…Ï‚ ÏƒÏ„Î± Î´ÎµÎ´Î¿Î¼Î­Î½Î± Î¼Îµ Î¸ÏŒÏÏ…Î²Î¿, Î´Î·Î». [x_input, y_noisy], Ï„Î·Ï‚
myCustFunc, Ï‡ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹ÏÎ½Ï„Î±Ï‚ Ï„Î·Î½ scipy.optimize.curve_fit.
"""

#Î§ÏÎ®ÏƒÎ· Ï„Î·Ï‚ Î¼ÎµÎ¸ÏŒÎ´Î¿Ï… ÎµÎ»Î±Ï‡Î¯ÏƒÏ„Ï‰Î½ Ï„ÎµÏ„ÏÎ±Î³ÏÎ½Ï‰Î½ Î³Î¹Î± Ï„Î·Î½ ÎµÏÏÎµÏƒÎ· Ï„Î·Ï‚ ÎºÎ±Î¼Ï€ÏÎ»Î·Ï‚ Ï€Î¿Ï… Ï€ÏÎ¿ÏƒÎµÎ³Î³Î¯Î¶ÎµÎ¹ Ï„Î± Î´ÎµÎ´Î¿Î¼Î­Î½Î± Î¼Îµ Î¸ÏŒÏÏ…Î²Î¿.
#Î•Ï€Î¹ÏƒÏ„ÏÎ­Ï†Î¿Î½Ï„Î±Î¹ Î· ÎµÎºÏ„Î¯Î¼Î·ÏƒÎ· Ï„Ï‰Î½ Ï€Î±ÏÎ±Î¼Î­Ï„ÏÏ‰Î½ ÎºÎ±Î¹ Î· ÏƒÏ…Î½Î´Î¹Î±ÎºÏÎ¼Î±Î½ÏƒÎ· Ï„Î¿Ï…Ï‚.
customPredictedParameters, customÎ•stimatedCovariance = opt.curve_fit(myCustFunc, sortedList, customNoisyList)

"""7. Î˜Î± Î¿ÏÎ¯ÏƒÎµÏ„Îµ Î¼Î¹Î± Î½Î­Î± ÏƒÏ…Î½Î¬ÏÏ„Î·ÏƒÎ·, Î¿Î½ÏŒÎ¼Î±Ï„Î¹ poly4thDegree(x, a, b, c, d, e): Î­Î½Î± Ï€Î¿Î»Ï…ÏÎ½Ï…Î¼Î¿ 4Î¿Ï…
Î²Î±Î¸Î¼Î¿Ï. Î ÏÎ¿ÏƒÎ¿Ï‡Î®: Î· ÏƒÏ…Î½Î¬ÏÏ„Î·ÏƒÎ· Î¸Î± Ï€ÏÎ­Ï€ÎµÎ¹ Î½Î± Î¿ÏÎ¹ÏƒÏ„ÎµÎ¯ Î¼Îµ Ï„Î­Ï„Î¿Î¹Î¿ Ï„ÏÏŒÏ€Î¿ ÏÏƒÏ„Îµ Î½Î± Î¼Ï€Î¿ÏÎµÎ¯ Î½Î±
Ï‡ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹Î·Î¸ÎµÎ¯ Î±Ï€ÏŒ Ï„Î·Î½ curve_fit(), Î³Î¹Î± Ï„Î·Î½ ÎµÎºÏ„Î¯Î¼Î·ÏƒÎ· Ï„Ï‰Î½ Ï€Î±ÏÎ±Î¼Î­Ï„ÏÏ‰Î½.
"""

#ÎŸÏÎ¹ÏƒÎ¼ÏŒÏ‚ ÏƒÏ…Î½Î±ÏÏ„Î®ÏƒÎµÏ‰Ï‚ Î· Î¿Ï€Î¿Î¯Î± Î´Î­Ï‡ÎµÏ„Î±Î¹ Ï„Î± ÏƒÏ„Î¿Î¹Ï‡ÎµÎ¯Î± ÎµÎ½ÏŒÏ‚ Ï€Î¯Î½Î±ÎºÎ± Ï‰Ï‚ ÏŒÏÎ¹ÏƒÎ¼Î± ÎºÎ±Î¹ Ï„Î± Ï‡ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹ÎµÎ¯ Î³Î¹Î± Ï„Î¿Î½ Ï…Ï€Î¿Î»Î¿Î³Î¹ÏƒÎ¼ÏŒ Ï„Î¹Î¼ÏÎ½ ÎµÎ½ÏŒÏ‚ Ï€Î¿Î»Ï…Ï‰Î½ÏÎ¼Î¿Ï… 4Î¿Ï… Î²Î±Î¸Î¼Î¿Ï.
#Î•Ï€Î¹ÏƒÏ„ÏÎ­Ï†ÎµÎ¹ Î­Î½Î±Î½ Ï€Î¯Î½Î±ÎºÎ± Î¯Î´Î¹Î¿Ï… Î¼ÎµÎ³Î­Î¸Î¿Ï…Ï‚ Î¼Îµ Ï„Î± Î½Î­Î± ÏƒÏ„Î¿Î¹Ï‡ÎµÎ¯Î±.
def poly4thDegree(myArray, a, b, c, d, e):
  anArray = (a*(myArray**4) + b*(myArray**3) + c*(myArray**2) + d*myArray + e)
  return anArray

"""8. Î§ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹ÏÎ½Ï„Î±Ï‚ Ï„Î¿ ÏƒÏÎ½Î¿Î»Î¿ Ï„Î¹Î¼ÏÎ½ Ï€Î¿Ï… Î­Ï‡ÎµÏ„Îµ Î´Î¹Î±Î¸Î­ÏƒÎ¹Î¼ÎµÏ‚, [x_input, y_noisy], Ï€ÏÎ¿ÏƒÎµÎ³Î³Î¯ÏƒÏ„Îµ
Ï„Î¹Ï‚ Ï€Î±ÏÎ±Î¼Î­Ï„ÏÎ¿Ï…Ï‚ Ï„Î¿Ï… Ï€Î¿Î»Ï…Ï‰Î½ÏÎ¼Î¿Ï….
"""

#Î”ÎµÏÏ„ÎµÏÎ· Ï‡ÏÎ®ÏƒÎ· Ï„Î·Ï‚ Î¼ÎµÎ¸ÏŒÎ´Î¿Ï… ÎµÎ»Î±Ï‡Î¯ÏƒÏ„Ï‰Î½ Ï„ÎµÏ„ÏÎ±Î³ÏÎ½Ï‰Î½ Î³Î¹Î± Ï„Î·Î½ ÎµÏÏÎµÏƒÎ· Ï„Î·Ï‚ ÎºÎ±Î¼Ï€ÏÎ»Î·Ï‚ Ï€Î¿Ï… Ï€ÏÎ¿ÏƒÎµÎ³Î³Î¯Î¶ÎµÎ¹ Ï„Î± Î´ÎµÎ´Î¿Î¼Î­Î½Î± Î¼Îµ Î¸ÏŒÏÏ…Î²Î¿.
#Î•Ï€Î¹ÏƒÏ„ÏÎ­Ï†Î¿Î½Ï„Î±Î¹ Î· ÎµÎºÏ„Î¯Î¼Î·ÏƒÎ· Ï„Ï‰Î½ Ï€Î±ÏÎ±Î¼Î­Ï„ÏÏ‰Î½ ÎºÎ±Î¹ Î· ÏƒÏ…Î½Î´Î¹Î±ÎºÏÎ¼Î±Î½ÏƒÎ· Ï„Î¿Ï…Ï‚.
polyPredictedParameters, polyEstimatedCovariance = opt.curve_fit(poly4thDegree, sortedList, customNoisyList)

"""9. Î˜Î± ÎºÎ¬Î½ÎµÏ„Îµ 2 Î´Î¹Î±Ï†Î¿ÏÎµÏ„Î¹ÎºÎ¬ plots Ï€Î¿Ï… Î¸Î± Î´ÎµÎ¯Ï‡Î½Î¿Ï…Î½ Ï„Î¹Ï‚ Ï€ÏÎ¿Î²Î»ÎµÏ†Î¸ÎµÎ¯ÏƒÎµÏ‚ Ï„Î¹Î¼Î­Ï‚ (y_predicted) ÏŒÏ„Î±Î½
Ï‡ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹ÎµÎ¯Ï„Îµ Ï„Î¹Ï‚ myCustFunc (ÎµÏÏ‰Ï„. 2) ÎºÎ±Î¹ poly4thDegree (ÎµÏÏ‰Ï„. 7).
a. Î£Ï„Î¿ 1Î¿ Î¸Î± Ï†Î±Î¯Î½Î¿Î½Ï„Î±Î¹ Î¿Î¹ Ï„Î¹Î¼Î­Ï‚ Ï„Î·Ï‚ myCustFunc Î¼Îµ Ï„Î¹Ï‚ Ï€Î±ÏÎ±Î¼Î­Ï„ÏÎ¿Ï…Ï‚ Ï€Î¿Ï… Ï€ÏÎ¿Î­ÎºÏ…ÏˆÎ±Î½
Î±Ï€ÏŒ Ï„Î¿ ÎµÏÏÏ„Î·Î¼Î± 6.
b. Î£Ï„Î¿ 2Î¿ Î¸Î± ÎºÎ¬Î½ÎµÏ„Îµ Î±ÎºÏÎ¹Î²ÏÏ‚ Ï„Î± Î¯Î´Î¹Î± Î³Î¹Î± Ï„Î·Î½ ÏƒÏ…Î½Î¬ÏÏ„Î·ÏƒÎ· poly4thDegree.
"""

#Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± Î»Î¯ÏƒÏ„Î±Ï‚ Ï„Î¹Î¼ÏÎ½ Ï„Î·Ï‚ ÏƒÏ…Î½Î¬ÏÏ„Î·ÏƒÎ·Ï‚ myCustFunc Î²Î±ÏƒÎ¹ÏƒÎ¼Î­Î½ÎµÏ‚ ÏƒÏ„Î¹Ï‚ ÎµÎºÏ„Î¹Î¼Î·Î¼Î­Î½ÎµÏ‚ Ï€Î±ÏÎ±Î¼Î­Ï„ÏÎ¿Ï…Ï‚ Î»1 ÎºÎ±Î¹ Î»2.
customPredictedList = myCustFunc(sortedList, *customPredictedParameters)

#Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± Î»Î¯ÏƒÏ„Î±Ï‚ Ï„Î¹Î¼ÏÎ½ Ï„Î·Ï‚ ÏƒÏ…Î½Î¬ÏÏ„Î·ÏƒÎ·Ï‚ poly4thDegree Î²Î±ÏƒÎ¹ÏƒÎ¼Î­Î½ÎµÏ‚ ÏƒÏ„Î¹Ï‚ ÎµÎºÏ„Î¹Î¼Î·Î¼Î­Î½ÎµÏ‚ Ï€Î±ÏÎ±Î¼Î­Ï„ÏÎ¿Ï…Ï‚ a, b, c, d, e.
polyPredictedList = poly4thDegree(sortedList, *polyPredictedParameters)

#Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± Ï€ÏÏÏ„Î¿Ï… Î³ÏÎ±Ï†Î®Î¼Î±Ï„Î¿Ï‚ Î¼Îµ Ï„Î·Î½ Ï€ÏÏŒÎ²Î»ÎµÏˆÎ· Ï„Î·Ï‚ ÏƒÏ…Î½Î¬ÏÏ„Î·ÏƒÎ·Ï‚ myCustFunc.
plt.plot(customPredictedList, 'r-', label = "myCustFunc()'s predicted values")
plt.legend()
plt.ylabel('Predicted Values')
plt.xlabel('Indices')
plt.title("Custom Function's Prediction")
plt.show()

#Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± Î´ÎµÏÏ„ÎµÏÎ¿Ï… Î³ÏÎ±Ï†Î®Î¼Î±Ï„Î¿Ï‚ Î¼Îµ Ï„Î·Î½ Ï€ÏÏŒÎ²Î»ÎµÏˆÎ· Ï„Î·Ï‚ ÏƒÏ…Î½Î¬ÏÏ„Î·ÏƒÎ·Ï‚ poly4thDegree.
plt.plot(polyPredictedList, 'b-', label = "poly4thDegree()'s predicted values")
plt.legend()
plt.ylabel('Predicted Values')
plt.xlabel('Indices')
plt.title("Polynomial Function's Prediction")
plt.show()

"""10. Î˜Î± Ï…Ï€Î¿Î»Î¿Î³Î¯ÏƒÎµÏ„Îµ Ï„Î± ÏƒÏ„Î±Ï„Î¹ÏƒÏ„Î¹ÎºÎ¬ ÏƒÏ†Î¬Î»Î¼Î±Ï„Î± mean absolute error ÎºÎ±Î¹ root mean squared error,
Î³Î¹Î± ÎºÎ¬Î¸Îµ Î­Î½Î± Î±Ï€ÏŒ Ï„Î¿Ï…Ï‚ Î±ÎºÏŒÎ»Î¿Ï…Î¸Î¿Ï…Ï‚ ÏƒÏ…Î½Î´Ï…Î±ÏƒÎ¼Î¿ÏÏ‚:
a. original_values - noisy_values
b. noisy_values - myCustFunc (Ï€Î±ÏÎ¬Î¼ÎµÏ„ÏÎ¿Î¹ Î±Ï€ÏŒ ÎµÏÏÏ„Î·Î¼Î± 6)
c. noisy_values - poly4thDegree (Ï€Î±ÏÎ¬Î¼ÎµÏ„ÏÎ¿Î¹ Î±Ï€ÏŒ ÎµÏÏÏ„Î·Î¼Î± 8)
"""

from sklearn.metrics import mean_absolute_error, mean_squared_error, max_error
#Î¥Ï€Î¿Î»Î¿Î³Î¹ÏƒÎ¼ÏŒÏ‚ ÎœÎ­ÏƒÎ¿Ï… Î‘Ï€ÏŒÎ»Ï…Ï„Î¿Ï… Î£Ï†Î¬Î»Î¼Î±Ï„Î¿Ï‚ (Mean Absolute Error) ÎºÎ±Î¹ Î¡Î¯Î¶Î±Ï‚ ÎœÎ­ÏƒÎ¿Ï… Î¤ÎµÏ„ÏÎ±Î³ÏÎ½Î¿Ï… Î£Ï†Î¬Î»Î¼Î±Ï„Î¿Ï‚ (Root Mean Square Error) Ï„Ï‰Î½ Î±ÎºÎ¿Î»Î¿ÏÎ¸Ï‰Î½ ÏƒÏ…Î½Î´Ï…Î±ÏƒÎ¼ÏÎ½:
#a) original_values - noisy_values
aMae = mean_absolute_error(customProcessedList, customNoisyList)
aRmse = np.sqrt(mean_squared_error(customProcessedList, customNoisyList))

#b) noisy_values - myCustFunc (Ï€Î±ÏÎ¬Î¼ÎµÏ„ÏÎ¿Î¹ Î±Ï€ÏŒ ÎµÏÏÏ„Î·Î¼Î± 6, ÎµÎºÏ„Î¯Î¼Î·ÏƒÎ· Ï„Î·Ï‚ myCustFunc)
bMae = mean_absolute_error(customNoisyList, customPredictedList)
bRmse = np.sqrt(mean_squared_error(customNoisyList, customPredictedList))

#c) noisy_values - poly4thDegree (Ï€Î±ÏÎ¬Î¼ÎµÏ„ÏÎ¿Î¹ Î±Ï€ÏŒ ÎµÏÏÏ„Î·Î¼Î± 8, ÎµÎºÏ„Î¯Î¼Î·ÏƒÎ· Ï„Î·Ï‚ poly4thDegree)
cMae = mean_absolute_error(customNoisyList, polyPredictedList)
cRmse = np.sqrt(mean_squared_error(customNoisyList, polyPredictedList))

"""Î¤Î± Ï€Î±ÏÎ±Ï€Î¬Î½Ï‰ ÏƒÏ†Î¬Î»Î¼Î±Ï„Î± Ï€ÏÎ­Ï€ÎµÎ¹ Î½Î± ÎµÎ¼Ï†Î±Î½Î¯Î¶Î¿Î½Ï„Î±Î¹ ÏƒÏ„Î·Î½ Î¿Î¸ÏŒÎ½Î· Î¼Î±Î¶Î¯ Î¼Îµ Î¼Î¹Î± Ï€ÏÏŒÏ„Î±ÏƒÎ· Ï€Î¿Ï… Î½Î±
ÎµÎ¾Î·Î³ÎµÎ¯ ÏƒÎµ Ï„Î¹ Î±Ï†Î¿ÏÎ¿ÏÎ½ Î¿Î¹ Î±ÏÎ¹Î¸Î¼Î¿Î¯ Ï€Î¿Ï… Î¼ÏŒÎ»Î¹Ï‚ Ï„Ï…Ï€ÏÎ¸Î·ÎºÎ±Î½.
Î ÏŒÏƒÎ¿ ÎºÎ±Î»Î® Ï€ÏÎ¿ÏƒÎ­Î³Î³Î¹ÏƒÎ· ÏƒÎ±Ï‚ Î´Î¯Î½ÎµÎ¹ Ï„Î¿ Ï€Î¿Î»Ï…ÏÎ½Ï…Î¼Î¿ Î³Î¹Î± Ï„Î¿ ÏƒÏ…Î³ÎºÎµÎºÏÎ¹Î¼Î­Î½Î¿ Ï€ÏÏŒÎ²Î»Î·Î¼Î±;
"""

print("ÎŸ ÏŒÏÎ¿Ï‚ Î£Ï†Î¬Î»Î¼Î± Î±Î½Î±Ï†Î­ÏÎµÏ„Î±Î¹ ÏƒÏ„Î· Î´Î¹Î±Ï†Î¿ÏÎ¬ Î¼ÎµÏ„Î±Î¾Ï Ï„Î·Ï‚ Ï€ÏÎ±Î³Î¼Î±Ï„Î¹ÎºÎ®Ï‚ Ï„Î¹Î¼Î®Ï‚ ÎµÎ½ÏŒÏ‚ ÏƒÏ„Î¿Î¹Ï‡ÎµÎ¯Î¿Ï… Î‘ ÎºÎ±Î¹ Î¼Î¯Î±Ï‚ ÎµÎºÏ„Î¯Î¼Î·ÏƒÎ·Ï‚ Ï„Î·Ï‚ Ï„Î¹Î¼Î®Ï‚ Î±Ï…Ï„Î®Ï‚ Î‘'.\n\
Î¤Î¿ ÎœÎ­ÏƒÎ¿ Î‘Ï€ÏŒÎ»Ï…Ï„Î¿ Î£Ï†Î¬Î»Î¼Î± (Mean Absolute Error) Ï„Î¿ Î¿Ï€Î¿Î¯Î¿ Ï…Ï€Î¿Î»Î¿Î³Î¯Î¶ÎµÏ„Î±Î¹ Î±Ï€Î¿ Ï„Î¿ Î¬Î¸ÏÎ¿Î¹ÏƒÎ¼Î± ÏŒÎ»Ï‰Î½ Ï„Ï‰Î½ Î±Ï€Î¿Î»ÏÏ„Ï‰Î½ ÏƒÏ†Î±Î»Î¼Î¬Ï„Ï‰Î½ Ï„Ï‰Î½ Ï€ÏÎ¿Î²Î»Î­ÏˆÎµÏ‰Î½ Î´Î¹Î±Î¹ÏÎµÎ¼Î­Î½Î¿ Î¼Îµ Ï„Î¿ Ï€Î»Î®Î¸Î¿Ï‚ Ï„Î¿Ï…Ï‚,\n\
ÎºÎ±Î¸ÏÏ‚ ÎºÎ±Î¹ Î· Î¡Î¯Î¶Î± Ï„Î¿Ï… ÎœÎ­ÏƒÎ¿Ï… Î¤ÎµÏ„ÏÎ±Î³ÏÎ½Î¿Ï… Î£Ï†Î¬Î»Î¼Î±Ï„Î¿Ï‚ (Root Mean Square Error), Î· Î¿Ï€Î¿Î¯Î± Ï…Ï€Î¿Î»Î¿Î³Î¯Î¶ÎµÏ„Î±Î¹\n\
Î±Ï€Î¿ Ï„Î·Î½ ÏÎ¯Î¶Î± Ï„Î¿Ï… Î±Î¸ÏÎ¿Î¯ÏƒÎ¼Î±Ï„Î¿Ï‚ ÏŒÎ»Ï‰Î½ Ï„Ï‰Î½ Ï„ÎµÏ„ÏÎ±Î³ÏÎ½Ï‰Î½ ÏƒÏ†Î±Î»Î¼Î¬Ï„Ï‰Î½ Ï„Ï‰Î½ Ï€ÏÎ¿Î²Î»Î­ÏˆÎµÏ‰Î½ Î´Î¹Î±Î¹ÏÎµÎ¼Î­Î½Î¿ Î¼Îµ Ï„Î¿ Ï€Î»Î®Î¸Î¿Ï‚ Ï„Î¿Ï…Ï‚,\n\
ÎµÎºÏ†ÏÎ¬Î¶Î¿Ï…Î½ Ï„Î·Î½ ÎµÎºÏ„Î¹Î¼ÏÎ¼ÎµÎ½Î· Î±Ï€ÏŒÎºÎ»Î¹ÏƒÎ· Ï€Î¿Ï… Î¸Î± Î­Ï‡ÎµÎ¹ Î¼Î¯Î± Ï€ÏÎ¿Î²Î»ÎµÎ¸ÎµÎ¯ÏƒÎ± Ï„Î¹Î¼Î® Î±Ï€Î¿ Ï„Î·Î½ Ï€ÏÎ±Î³Î¼Î±Ï„Î¹ÎºÎ® Ï„Î·Ï‚ Î±Î¾Î¯Î±.\n")

print("Î¥Ï€Î¿Î»Î¿Î³Î¹ÏƒÎ¼ÏŒÏ‚ ÎœÎ­ÏƒÎ¿Ï… Î‘Ï€ÏŒÎ»Ï…Ï„Î¿Ï… Î£Ï†Î¬Î»Î¼Î±Ï„Î¿Ï‚ (Mean Absolute Error) ÎºÎ±Î¹ Î¡Î¯Î¶Î±Ï‚ ÎœÎ­ÏƒÎ¿Ï… Î¤ÎµÏ„ÏÎ±Î³ÏÎ½Î¿Ï… Î£Ï†Î¬Î»Î¼Î±Ï„Î¿Ï‚ (Root Mean Square Error) Ï„Ï‰Î½ Î±ÎºÎ¿Î»Î¿ÏÎ¸Ï‰Î½ ÏƒÏ…Î½Î´Ï…Î±ÏƒÎ¼ÏÎ½:\n")

print("a) original values - noisy values (Î¼Î­ÏƒÎ· Î´Î¹Î±Ï†Î¿ÏÎ¬ Ï„Ï‰Î½ Ï€ÏÎ±Î³Î¼Î±Ï„Î¹ÎºÏÎ½ Î±Ï€Î¿ Ï„Î± Î±Î»Î»Î¿Î¹Ï‰Î¼Î­Î½Î± Î»ÏŒÎ³Ï‰ Ï„Î¿Ï… Î¸Î¿ÏÏÎ²Î¿Ï… Î´ÎµÎ´Î¿Î¼Î­Î½Î±)")
print("   myCustFunc - Mean absolute error is: {:.2f}".format(aMae))
print("   myCustFunc - Root mean squared error is: {:.2f}".format(aRmse))

print("\nb) noisy values - myCustFunc (Ï€Î±ÏÎ¬Î¼ÎµÏ„ÏÎ¿Î¹ Î±Ï€ÏŒ ÎµÏÏÏ„Î·Î¼Î± 6, Î¼Î­ÏƒÎ· Î´Î¹Î±Ï†Î¿ÏÎ¬ Ï„Ï‰Î½ Î±Î»Î»Î¿Î¹Ï‰Î¼Î­Î½Ï‰Î½ ÎºÎ±Î¹ Ï„Ï‰Î½ Ï€ÏÎ¿Î²Î»ÎµÏ†Î¸Î­Î½Ï„Ï‰Î½ Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½ Ï„Î·Ï‚ ÏƒÏ…Î½Î¬ÏÏ„Î·ÏƒÎ·Ï‚ myCustFunc)")
print("   myCustFunc - Mean absolute error is: {:.2f}".format(bMae))
print("   myCustFunc - Root mean squared error is: {:.2f}".format(bRmse))

print("\nc) noisy values - poly4thDegree (Ï€Î±ÏÎ¬Î¼ÎµÏ„ÏÎ¿Î¹ Î±Ï€ÏŒ ÎµÏÏÏ„Î·Î¼Î± 8, Î¼Î­ÏƒÎ· Î´Î¹Î±Ï†Î¿ÏÎ¬ Ï„Ï‰Î½ Î±Î»Î»Î¿Î¹Ï‰Î¼Î­Î½Ï‰Î½ ÎºÎ±Î¹ Ï„Ï‰Î½ Ï€ÏÎ¿Î²Î»ÎµÏ†Î¸Î­Î½Ï„Ï‰Î½ Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½ Ï„Î·Ï‚ ÏƒÏ…Î½Î¬ÏÏ„Î·ÏƒÎ·Ï‚ poly4thDegree)")
print("   poly4thDegree - Mean absolute error is: {:.2f}".format(cMae))
print("   poly4thDegree - Root mean squared error is: {:.2f}".format(cRmse))

print("\nÎ— Ï€ÏÎ¿ÏƒÎ­Î³Î³Î¹ÏƒÎ· Ï„Î·Ï‚ poly4thDegree Î³Î¹Î± Ï„Î¿ ÏƒÏ…Î³ÎºÎµÎºÏÎ¹Î¼Î­Î½Î¿ Ï€ÏÏŒÎ²Î»Î·Î¼Î± ÎµÎ¯Î½Î±Î¹ Ï€Î¬ÏÎ± Ï€Î¿Î»Ï ÎºÎ±Î»Î®,\n\
ÏŒÏ€Ï‰Ï‚ Î´ÎµÎ¯Ï‡Î½Î¿Ï…Î½ Ï„Î± Ï‡Î±Î¼Î·Î»Î¬ ÎºÎ±Î¹ ÎºÎ¿Î½Ï„Î¬ ÏƒÏ„Î¿ Î¼Î·Î´Î­Î½ Mean Absolute Error = {:.2f}".format(cMae),"ÎºÎ±Î¹ Root Mean Squared Error = {:.2f}.".format(cRmse),"\n\
ÎŒÎ¼Ï‰Ï‚, Î· Ï€ÏÎ¿ÏƒÎ­Î³Î³Î¹ÏƒÎ· Ï„Î·Ï‚ myCustFunc ÎµÎ¯Î½Î±Î¹ Î±ÎºÏŒÎ¼Î± ÎºÎ±Î»ÏÏ„ÎµÏÎ· (RMSE poly4th: {:.2f}".format(cRmse), "> RMSE custFunc: {:.2f})".format(bRmse),)

"""2o Î¼Î­ÏÎ¿Ï‚: Ï€ÏÎ¿ÏƒÎ­Î³Î³Î¹ÏƒÎ· ÎºÎ±Ï„Î¬ÏƒÏ„Î±ÏƒÎ·Ï‚ Î²Î±ÏƒÎ¹Î¶ÏŒÎ¼ÎµÎ½Î¿Î¹ Î¼ÏŒÎ½Î¿ ÏƒÏ„Î¹Ï‚ Î¼ÎµÏ„ÏÎ®ÏƒÎµÎ¹Ï‚ Ï€Î¿Ï… Î­Ï‡ÎµÏ„Îµ Î»Î¬Î²ÎµÎ¹ (Ï…Ï€Î¿Î¸Î­Ï„ÎµÏ„Îµ
ÏŒÏ„Î¹ Ï…Ï€Î¬ÏÏ‡ÎµÎ¹ Î¸ÏŒÏÏ…Î²Î¿Ï‚ ÏƒÏ„Î¹Ï‚ Î¼ÎµÏ„ÏÎ®ÏƒÎµÎ¹Ï‚, Î´ÎµÎ½ Î­Ï‡ÎµÏ„Îµ ÎºÎ¬Ï€Î¿Î¹Î± Î³Î½ÏÏƒÎ· ÏƒÏ‡ÎµÏ„Î¹ÎºÎ® Î¼Îµ Ï„Î¿ Î¼Î¿Î½Ï„Î­Î»Î¿ Ï€Î¿Ï…
Î´Î·Î¼Î¹Î¿Ï…ÏÎ³ÎµÎ¯ Ï„Î± Î´ÎµÎ´Î¿Î¼Î­Î½Î±).

1. Î§ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹ÎµÎ¯ÏƒÏ„Îµ Ï„Î¹Ï‚ 150 Ï„Î¹Î¼Î­Ï‚, *Î¼Îµ Î¸ÏŒÏÏ…Î²Î¿*, Ï€Î¿Ï… Î´Î·Î¼Î¹Î¿Ï…ÏÎ³Î®ÏƒÎ±Ï„Îµ ÏƒÏ„Î¿ 1Î¿ Î¼Î­ÏÎ¿Ï‚.
"""

print("ÎŸÎ¹ 150 Ï„Î¯Î¼ÎµÏ‚ Î¼Îµ Î¸ÏŒÏÏ…Î²Î¿ Ï€Î¿Ï… Î´Î·Î¼Î¹Î¿Ï…ÏÎ³Î®Î¸Î·ÎºÎ±Î½ ÏƒÏ„Î¿ 1Î¿ Î¼Î­ÏÎ¿Ï‚ ÎºÎ±Î¹ Î¸Î± Ï‡ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹Î·Î¸Î¿ÏÎ½ ÏƒÏ„Î¿ 2Î¿ Î¼Î­ÏÎ¿Ï‚ Ï„Î·Ï‚ ÎµÏÎ³Î±ÏƒÎ¯Î±Ï‚ ÎµÎ¯Î½Î±Î¹ Î¿Î¹ ÎµÎ¾Î®Ï‚: \n",*customNoisyList)

"""2. Î”Î¹Î±Ï‡Ï‰ÏÎ¯ÏƒÏ„Îµ Ï„Î± Î´Î¹Î±Î¸Î­ÏƒÎ¹Î¼Î± Î´ÎµÎ´Î¿Î¼Î­Î½Î±, [x_input, y_noisy], ÏƒÎµ Ï„ÏÎ¯Î± ÎµÏ€Î¹Î¼Î­ÏÎ¿Ï…Ï‚ Ï…Ï€Î¿ÏƒÏÎ½Î¿Î»Î±:
train, validation, ÎºÎ±Î¹ test.
"""

#Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± Ï€Î¯Î½Î±ÎºÎ± Î¼Îµ Ï„Ï…Ï‡Î±Î¯Î¿Ï…Ï‚ Î±ÏÎ¹Î¸Î¼Î¿ÏÏ‚ Î±Ï€Î¿ Ï„Î¿ 0 Î­Ï‰Ï‚ Ï„Î¿ 149. ÎŸÎ¹ Î±ÏÎ¹Î¸Î¼Î¿Î¯ Î±Ï…Ï„Î¿Î¯ Î¸Î± Ï‡ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹Î·Î¸Î¿ÏÎ½ Ï‰Ï‚ Î´ÎµÎ¯ÎºÏ„ÎµÏ‚ Ï€Î¯Î½Î±ÎºÎ±.
indexes = np.random.permutation(150)

#Î¥Ï€Î¿Î»Î¿Î³Î¹ÏƒÎ¼ÏŒÏ‚ Ï„Î¿Ï… Ï€Î¿ÏƒÎ¿ÏƒÏ„Î¿Ï Ï„Ï‰Î½ ÏƒÏ…Î½Î¿Î»Î¹ÎºÏÎ½ Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½ Ï„Î¿ Î¿Ï€Î¿Î¯Î¿ Î¸Î± Ï†Î¹Î»Î¿Î¾ÎµÎ½ÎµÎ¯ ÎºÎ¬Î¸Îµ Ï…Ï€Î¿ÏƒÏÎ½Î¿Î»Î¿.
trainDatPerc = 0.7
valDatPerc = trainDatPerc / 10
testDatPec = 1 - trainDatPerc - valDatPerc

#ÎšÎ±Ï„Î±Î¼ÎµÏÎ¹ÏƒÎ¼ÏŒÏ‚ Ï„Ï‰Î½ Î´Î¹Î±Î¸Î­ÏƒÎ¹Î¼Ï‰Î½ Î´ÎµÎ¹ÎºÏ„ÏÎ½ ÏƒÎµ Ï€Î¯Î½Î±ÎºÎµÏ‚
trainInd = indexes[0:int(trainDatPerc*len(indexes))]
valInd = indexes[int(trainDatPerc*len(indexes) + 1):int((trainDatPerc+valDatPerc)*len(indexes))]
testInd = indexes[int((trainDatPerc+valDatPerc)*len(indexes)) + 1:]

#Î ÏÎ¿ÏƒÎ±ÏÎ¼Î¿Î³Î® Ï„Ï‰Î½ Î´Î¹Î±ÏƒÏ„Î¬ÏƒÎµÏ‰Î½ Ï„Î¿Ï… Ï€Î¯Î½Î±ÎºÎ± Î³Î¹Î± Ï„Î·Î½ ÎµÎºÏ€Î±Î¯Î´ÎµÏ…ÏƒÎ· Ï„Ï‰Î½ Î¼Î¿Î½Ï„Î­Î»Ï‰Î½.
sortedList = sortedList.reshape(-1,1)

#Î”Î¹Î±Î¼Î¿Î¹ÏÎ±ÏƒÎ¼ÏŒÏ‚ Ï„Ï‰Î½ Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½ Î±Ï€Î¿ Ï„Î¹Ï‚ Î±ÏÏ‡Î¹ÎºÎ­Ï‚ Î»Î¯ÏƒÏ„ÎµÏ‚ sortedList ÎºÎ±Î¹ customNoisyList ÏƒÎµ Ï…Ï€Î¿ÏƒÏÎ½Î¿Î»Î± Î¼Îµ Ï‡ÏÎ®ÏƒÎ· Ï„Ï‰Î½ Î±Î½Ï„Î¯ÏƒÏ„Î¿Î¹Ï‡Ï‰Î½ Ï€Î¹Î½Î¬ÎºÏ‰Î½ Î´ÎµÎ¹ÎºÏ„ÏÎ½
trainingInput = sortedList[trainInd]
trainingOutput = customNoisyList[trainInd]
valInput = sortedList[valInd]
valOutput = customNoisyList[valInd]
testInput = sortedList[testInd]
testOutput = customNoisyList[testInd]

"""3. Î•ÎºÏ€Î±Î¹Î´ÎµÏÏƒÏ„Îµ Ï„ÏÎµÎ¹Ï‚ Î´Î¹Î±Ï†Î¿ÏÎµÏ„Î¹ÎºÎ¿ÏÏ‚ regressors (Ï€.Ï‡. kNN, SVR, Îº.Î»Ï€.) Ï„Î·Ï‚ ÎµÏ€Î¹Î»Î¿Î³Î®Ï‚ ÏƒÎ±Ï‚, Ï€Î¬Î½Ï‰
ÏƒÏ„Î¿ train set.
"""

#Î•ÎºÏ€Î±Î¯Î´ÎµÏ…ÏƒÎ· kNN regressor ÏƒÏ„Î¿ trainingInput
from sklearn.neighbors import KNeighborsRegressor
knnReg = KNeighborsRegressor(n_neighbors = 1)
knnReg = knnReg.fit(trainingInput, trainingOutput)

#Î•ÎºÏ€Î±Î¯Î´ÎµÏ…ÏƒÎ· SVR regressor ÏƒÏ„Î¿ trainingInput
from sklearn.svm import SVR
svmReg = SVR(kernel = 'rbf')
svmReg = svmReg.fit(trainingInput, trainingOutput)

#Î•ÎºÏ€Î±Î¯Î´ÎµÏ…ÏƒÎ· Polynomial regressor ÏƒÏ„Î¿ trainingInput
from sklearn.preprocessing import PolynomialFeatures
from sklearn.linear_model import LinearRegression
poly = PolynomialFeatures(degree = 7, include_bias = False)
poly_features = poly.fit_transform(trainingInput)
polyReg = LinearRegression()
polyReg = polyReg.fit(poly_features, trainingOutput)

"""*4*. Î‘Î¾Î¹Î¿Î»Î¿Î³Î®ÏƒÏ„Îµ Ï„Î·Î½ Î±Ï€ÏŒÎ´Î¿ÏƒÎ· Ï„Ï‰Î½ regressors Ï€Î¬Î½Ï‰ ÏƒÏ„Î¿ test set ÎºÎ±Î¹ Î´Î·Î¼Î¹Î¿Ï…ÏÎ³ÎµÎ¯ÏƒÏ„Îµ ÎºÎ±Ï„Î¬Î»Î»Î·Î»ÎµÏ‚
Î³ÏÎ±Ï†Î¹ÎºÎ­Ï‚ Ï€Î±ÏÎ±ÏƒÏ„Î¬ÏƒÎµÎ¹Ï‚ Ï€Î¿Ï… Î½Î± Ï†Î±Î¯Î½Î¿Î½Ï„Î±Î¹ Ï„Î± Î±Ï€Î¿Ï„ÎµÎ»Î­ÏƒÎ¼Î±Ï„Î±.
"""

#Î ÏÏŒÎ²Î»ÎµÏˆÎ· Î¼Îµ Î²Î¬ÏƒÎ· Ï„Î¿ test data set.
predictedOutputsknn = knnReg.predict(testInput)
predictedOutputssvm = svmReg.predict(testInput)
predictedOutputspoly = polyReg.predict(poly.transform(testInput))

#Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± Î³ÏÎ±Ï†Î®Î¼Î±Ï„Î¿Ï‚ Î¼Îµ Ï„Î¹Ï‚ Ï€ÏÎ±Î³Î¼Î±Ï„Î¹ÎºÎ­Ï‚ Ï„Î¹Î¼Î­Ï‚ ÎºÎ±Î¹ Ï„Î¹Ï‚ ÎµÎºÏ„Î¹Î¼Î·Î¼Î­Î½ÎµÏ‚ Ï„Î¹Î¼Î­Ï‚ Ï„Ï‰Î½ Î¼Î¿Î½Ï„Î­Î»Ï‰Î½.
plt.figure(figsize=(12, 4))
plt.plot(testOutput,'rx', label = 'Target Values', markersize = 4)
plt.plot(predictedOutputsknn, 'r-', label = 'kNN')
plt.plot(predictedOutputssvm, 'g-', label = 'SVM')
plt.plot(predictedOutputspoly, 'b-', label = 'Polynomial')
plt.legend(loc = 'best')
plt.title("Test Set Prediction Results")
plt.xlabel("Index")
plt.ylabel("Value")
plt.show()

#Î¥Ï€Î¿Î»Î¿Î³Î¹ÏƒÎ¼ÏŒÏ‚ ÎœÎ­ÏƒÎ¿Ï… Î‘Ï€ÏŒÎ»Ï…Ï„Î¿Ï… Î£Ï†Î¬Î»Î¼Î±Ï„Î¿Ï‚ (Mean Absolute Error), Î¡Î¯Î¶Î±Ï‚ ÎœÎ­ÏƒÎ¿Ï… Î¤ÎµÏ„ÏÎ±Î³ÏÎ½Î¿Ï… Î£Ï†Î¬Î»Î¼Î±Ï„Î¿Ï‚ (Root Mean Square Error) ÎºÎ±Î¹ ÎœÎµÎ³Î¯ÏƒÏ„Î¿Ï… Î£Ï†Î¬Î»Î¼Î±Ï„Î¿Ï‚ (Maximum Error) Ï„Ï‰Î½ Î±ÎºÎ¿Î»Î¿ÏÎ¸Ï‰Î½ ÏƒÏ…Î½Î´Ï…Î±ÏƒÎ¼ÏÎ½:
#a) Î ÏÎ±Î³Î¼Î±Ï„Î¹ÎºÎ­Ï‚ Î¤Î¹Î¼Î­Ï‚ - Î ÏÎ¿Î²Î»ÎµÏ†Î¸ÎµÎ¯ÏƒÎµÏ‚ Î¤Î¹Î¼Î­Ï‚ Ï„Î¿Ï… Î¼Î¿Î½Ï„Î­Î»Î¿Ï… kNN
mae_knn = mean_absolute_error(testOutput, predictedOutputsknn)
rmse_knn = np.sqrt(mean_squared_error(testOutput, predictedOutputsknn))
max_knn = max_error(testOutput, predictedOutputsknn)

#b) Î ÏÎ±Î³Î¼Î±Ï„Î¹ÎºÎ­Ï‚ Î¤Î¹Î¼Î­Ï‚ - Î ÏÎ¿Î²Î»ÎµÏ†Î¸ÎµÎ¯ÏƒÎµÏ‚ Î¤Î¹Î¼Î­Ï‚ Ï„Î¿Ï… Î¼Î¿Î½Ï„Î­Î»Î¿Ï… SVM
mae_svm = mean_absolute_error(testOutput, predictedOutputssvm)
rmse_svm = np.sqrt(mean_squared_error(testOutput, predictedOutputssvm))
max_svm = max_error(testOutput, predictedOutputssvm)

#c) Î ÏÎ±Î³Î¼Î±Ï„Î¹ÎºÎ­Ï‚ Î¤Î¹Î¼Î­Ï‚ - Î ÏÎ¿Î²Î»ÎµÏ†Î¸ÎµÎ¯ÏƒÎµÏ‚ Î¤Î¹Î¼Î­Ï‚ Ï„Î¿Ï… Î Î¿Î»Ï…Ï‰Î½Ï…Î¼Î¹ÎºÎ¿Ï Î¼Î¿Î½Ï„Î­Î»Î¿Ï…
mae_poly = mean_absolute_error(testOutput, predictedOutputspoly)
rmse_poly = np.sqrt(mean_squared_error(testOutput, predictedOutputspoly))
max_poly = max_error(testOutput, predictedOutputspoly)

#Î•ÎºÏ„ÏÏ€Ï‰ÏƒÎ· Ï„Ï‰Î½ Ï„Î¹Î¼ÏÎ½.
print("\nÎ¥Ï€Î¿Î»Î¿Î³Î¹ÏƒÎ¼ÏŒÏ‚ ÎœÎ­ÏƒÎ¿Ï… Î‘Ï€ÏŒÎ»Ï…Ï„Î¿Ï… Î£Ï†Î¬Î»Î¼Î±Ï„Î¿Ï‚ (Mean Absolute Error), Î¡Î¯Î¶Î±Ï‚ ÎœÎ­ÏƒÎ¿Ï… Î¤ÎµÏ„ÏÎ±Î³ÏÎ½Î¿Ï… Î£Ï†Î¬Î»Î¼Î±Ï„Î¿Ï‚ (Root Mean Square Error) ÎºÎ±Î¹ ÎœÎµÎ³Î¯ÏƒÏ„Î¿Ï… Î£Ï†Î¬Î»Î¼Î±Ï„Î¿Ï‚ (Maximum Error) Ï„Ï‰Î½ Î±ÎºÎ¿Î»Î¿ÏÎ¸Ï‰Î½ ÏƒÏ…Î½Î´Ï…Î±ÏƒÎ¼ÏÎ½: \n")
print("a) Î ÏÎ±Î³Î¼Î±Ï„Î¹ÎºÎ­Ï‚ Î¤Î¹Î¼Î­Ï‚ - Î ÏÎ¿Î²Î»ÎµÏ†Î¸ÎµÎ¯ÏƒÎµÏ‚ Î¤Î¹Î¼Î­Ï‚ Ï„Î¿Ï… Î¼Î¿Î½Ï„Î­Î»Î¿Ï… kNN")
print("   Mean absolute error is: {:.2f}".format(mae_knn))
print("   Root mean squared error is: {:.2f}".format(rmse_knn))
print("   Maximum error is: {:.2f}\n".format(max_knn))

print("b) Î ÏÎ±Î³Î¼Î±Ï„Î¹ÎºÎ­Ï‚ Î¤Î¹Î¼Î­Ï‚ - Î ÏÎ¿Î²Î»ÎµÏ†Î¸ÎµÎ¯ÏƒÎµÏ‚ Î¤Î¹Î¼Î­Ï‚ Ï„Î¿Ï… Î¼Î¿Î½Ï„Î­Î»Î¿Ï… SVM")
print("   Mean absolute error is: {:.2f}".format(mae_svm))
print("   Root mean squared error is: {:.2f}".format(rmse_svm))
print("   Maximum error is: {:.2f}\n".format(max_svm))

print("c) Î ÏÎ±Î³Î¼Î±Ï„Î¹ÎºÎ­Ï‚ Î¤Î¹Î¼Î­Ï‚ - Î ÏÎ¿Î²Î»ÎµÏ†Î¸ÎµÎ¯ÏƒÎµÏ‚ Î¤Î¹Î¼Î­Ï‚ Ï„Î¿Ï… Î Î¿Î»Ï…Ï‰Î½Ï…Î¼Î¹ÎºÎ¿Ï Î¼Î¿Î½Ï„Î­Î»Î¿Ï…")
print("   Mean absolute error is: {:.2f}".format(mae_poly))
print("   Root mean squared error is: {:.2f}".format(rmse_poly))
print("   Maximum error is: {:.2f}".format(max_poly))

#Î‘Î¾Î¹Î¿Î»ÏŒÎ³Î·ÏƒÎ· Ï„Î·Ï‚ Î±Ï€ÏŒÎ´Î¿ÏƒÎ·Ï‚ Ï„Ï‰Î½ regressors.
print("\nÎ£ÏÎ¼Ï†Ï‰Î½Î± Î¼Îµ Ï„Î± Mean Absolute Error ÎºÎ±Î¹ Root Mean Squared Error ÎµÎ¯Î½Î±Î¹ ÎµÎ¼Ï†Î±Î½Î­Ï‚ ÏŒÏ„Î¹ Ï„Î¿ Î Î¿Î»Ï…Ï‰Î½Ï…Î¼Î¹ÎºÏŒ Î¼Î¿Î½Ï„Î­Î»Î¿ \n\
ÎµÎ¯Î½Î±Î¹ Ï„Î¿ ÎºÎ±Î»ÏÏ„ÎµÏÎ¿ Î±Ï€Î¿ Ï„Î± Ï„ÏÎ¯Î±. ÎˆÏ‡ÎµÎ¹ Ï„Î¹Ï‚ Ï€Î¹Î¿ Ï‡Î±Î¼Î·Î»Î­Ï‚ Î±Ï€Î¿ÎºÎ»Î¯ÏƒÎµÎ¹Ï‚ ÏƒÎµ ÏƒÏ‡Î­ÏƒÎ· Î¼Îµ Ï„Î± Ï…Ï€ÏŒÎ»Î¿Î¹Ï€Î± ÎµÎºÏ€Î±Î¹Î´ÎµÏ…Î¼Î­Î½Î± Î¼Î¿Î½Ï„Î­Î»Î±,\n\
ÎµÎ½Ï ÏƒÏ„Î· Î´ÎµÏÏ„ÎµÏÎ· Î¸Î­ÏƒÎ· Î±ÎºÎ¿Î»Î¿Ï…Î¸ÎµÎ¯ Ï„Î¿ Î¼Î¿Î½Ï„Î­Î»Î¿ kNN Î¼Îµ Î»Î¯Î³Î¿ Î¼ÎµÎ³Î±Î»ÏÏ„ÎµÏÎµÏ‚ Î±Ï€Î¿ÎºÎ»Î¯ÏƒÎµÎ¹Ï‚. Î‘Î½Ï„Î¯Î¸ÎµÏ„Î± Î· Ï€ÎµÏÎ¯Ï€Ï„Ï‰ÏƒÎ· Ï„Î¿Ï… \n\
SVM Î¼Î¿Î½Ï„Î­Î»Î¿Ï… Ï€Î±ÏÎ¿Ï…ÏƒÎ¹Î¬Î¶ÎµÎ¹ Ï€ÏÎ¿Î²Î»Î­ÏˆÎµÎ¹Ï‚ Î±Î½Î±ÎºÏÎ¹Î²ÎµÎ¯Ï‚ Î¼Îµ Ï…Ï€Î­ÏÎ¼ÎµÏ„ÏÎ¿ Maximum Error ÎºÎ±Î¹ Ï…ÏˆÎ·Î»Î­Ï‚ Î±Ï€Î¿ÎºÎ»Î¯ÏƒÎµÎ¹Ï‚ Î±Ï€Î¿ Ï„Î¹Ï‚ Ï€ÏÎ±Î³Î¼Î±Ï„Î¹ÎºÎ­Ï‚ Ï„Î¹Î¼Î­Ï‚.")

"""5. Î•Ï€Î±Î½Î±Î»Î¬Î²ÎµÏ„Îµ Ï„Î± Î²Î®Î¼Î±Ï„Î± 2 Î­Ï‰Ï‚ 4, Î±Î»Î»Î¬ Î±Ï…Ï„Î® Ï„Î·Î½ Ï†Î¿ÏÎ¬ ÎºÎ±Î½Î¿Î½Î¹ÎºÎ¿Ï€Î¿Î¹ÎµÎ¯ÏƒÏ„Îµ Ï„Î¹Ï‚ Ï„Î¹Î¼Î­Ï‚ ÎµÎ¹ÏƒÏŒÎ´Î¿Ï…
ÏƒÏ„Î¿ Î´Î¹Î¬ÏƒÏ„Î·Î¼Î± [0,1]
"""

#ÎšÎ±Î½Î¿Î½Î¹ÎºÎ¿Ï€Î¿Î¯ÏƒÎ· Ï„Ï‰Î½ Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½ ÏƒÏ„Î¿ Î´Î¹Î¬ÏƒÏ„Î·Î¼Î± [0,1].
from sklearn.preprocessing import MinMaxScaler
scaler_inputs = MinMaxScaler(feature_range = (0, 1))

scaledTrainingInput = scaler_inputs.fit_transform(trainingInput)
scaledValInput = scaler_inputs.transform(valInput)
scaledTestInput = scaler_inputs.transform(testInput)

scaledTrainingOutput = scaler_inputs.transform(trainingOutput.reshape(-1,1))
scaledValOutput = scaler_inputs.transform(valOutput.reshape(-1,1))
scaledTestOutput = scaler_inputs.transform(testOutput.reshape(-1,1))

#Î•ÎºÏ€Î±Î¯Î´ÎµÏ…ÏƒÎ· kNN regressor ÏƒÏ„Î¿ scaledTrainingInput
knnReg = KNeighborsRegressor(n_neighbors = 1)
knnReg.fit(scaledTrainingInput, scaledTrainingOutput)

#Î•ÎºÏ€Î±Î¯Î´ÎµÏ…ÏƒÎ· SVR regressor ÏƒÏ„Î¿ scaledTrainingInput
svmReg = SVR(kernel = 'rbf')
svmReg.fit(scaledTrainingInput, scaledTrainingOutput.ravel())

#Î•ÎºÏ€Î±Î¯Î´ÎµÏ…ÏƒÎ· Polynomial regressor ÏƒÏ„Î¿ scaledTrainingInput
poly = PolynomialFeatures(degree = 7, include_bias = False)
poly_features = poly.fit_transform(scaledTrainingInput)
polyReg = LinearRegression()
polyReg.fit(poly_features, scaledTrainingOutput)

#Î ÏÏŒÎ²Î»ÎµÏˆÎ· Î¼Îµ Î²Î¬ÏƒÎ· Ï„Î¿ scaled test data set.
predictedOutputsknn = knnReg.predict(scaledTestInput)
predictedOutputssvm = svmReg.predict(scaledTestInput)
predictedOutputspoly = polyReg.predict(poly.fit_transform(scaledTestInput))

#Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± Î³ÏÎ±Ï†Î®Î¼Î±Ï„Î¿Ï‚ Î¼Îµ Ï„Î¹Ï‚ Ï€ÏÎ±Î³Î¼Î±Ï„Î¹ÎºÎ­Ï‚ Ï„Î¹Î¼Î­Ï‚ ÎºÎ±Î¹ Ï„Î¹Ï‚ ÎµÎºÏ„Î¹Î¼Î·Î¼Î­Î½ÎµÏ‚ Ï„Î¹Î¼Î­Ï‚ Ï„Ï‰Î½ Î¼Î¿Î½Ï„Î­Î»Ï‰Î½.
plt.figure(figsize=(12, 4))
plt.plot(scaledTestOutput, 'rx', label = 'Target Values', markersize = 4)
plt.plot(predictedOutputsknn, 'r-', label = 'kNN')
plt.plot(predictedOutputssvm, 'g-', label = 'SVM')
plt.plot(predictedOutputspoly, 'b-', label = 'Polynomial')
plt.legend(loc='best')
plt.title("Test Set Prediction Results (Normalised Inputs)")
plt.xlabel("Index")
plt.ylabel("Value")
plt.show()

#Î¥Ï€Î¿Î»Î¿Î³Î¹ÏƒÎ¼ÏŒÏ‚ ÎœÎ­ÏƒÎ¿Ï… Î‘Ï€ÏŒÎ»Ï…Ï„Î¿Ï… Î£Ï†Î¬Î»Î¼Î±Ï„Î¿Ï‚ (Mean Absolute Error), Î¡Î¯Î¶Î±Ï‚ ÎœÎ­ÏƒÎ¿Ï… Î¤ÎµÏ„ÏÎ±Î³ÏÎ½Î¿Ï… Î£Ï†Î¬Î»Î¼Î±Ï„Î¿Ï‚ (Root Mean Square Error) ÎºÎ±Î¹ ÎœÎµÎ³Î¯ÏƒÏ„Î¿Ï… Î£Ï†Î¬Î»Î¼Î±Ï„Î¿Ï‚ (Maximum Error) Ï„Ï‰Î½ Î±ÎºÎ¿Î»Î¿ÏÎ¸Ï‰Î½ ÏƒÏ…Î½Î´Ï…Î±ÏƒÎ¼ÏÎ½:
#a) Î ÏÎ±Î³Î¼Î±Ï„Î¹ÎºÎ­Ï‚ Î¤Î¹Î¼Î­Ï‚ - Î ÏÎ¿Î²Î»ÎµÏ†Î¸ÎµÎ¯ÏƒÎµÏ‚ Î¤Î¹Î¼Î­Ï‚ Ï„Î¿Ï… Î¼Î¿Î½Ï„Î­Î»Î¿Ï… kNN
mae_knn = mean_absolute_error(scaledTestOutput, predictedOutputsknn)
rmse_knn = np.sqrt(mean_squared_error(scaledTestOutput, predictedOutputsknn))
max_knn = max_error(scaledTestOutput, predictedOutputsknn)

#b) Î ÏÎ±Î³Î¼Î±Ï„Î¹ÎºÎ­Ï‚ Î¤Î¹Î¼Î­Ï‚ - Î ÏÎ¿Î²Î»ÎµÏ†Î¸ÎµÎ¯ÏƒÎµÏ‚ Î¤Î¹Î¼Î­Ï‚ Ï„Î¿Ï… Î¼Î¿Î½Ï„Î­Î»Î¿Ï… SVM
mae_svm = mean_absolute_error(scaledTestOutput, predictedOutputssvm)
rmse_svm = np.sqrt(mean_squared_error(scaledTestOutput, predictedOutputssvm))
max_svm = max_error(scaledTestOutput, predictedOutputssvm)

#c) Î ÏÎ±Î³Î¼Î±Ï„Î¹ÎºÎ­Ï‚ Î¤Î¹Î¼Î­Ï‚ - Î ÏÎ¿Î²Î»ÎµÏ†Î¸ÎµÎ¯ÏƒÎµÏ‚ Î¤Î¹Î¼Î­Ï‚ Ï„Î¿Ï… Î Î¿Î»Ï…Ï‰Î½Ï…Î¼Î¹ÎºÎ¿Ï Î¼Î¿Î½Ï„Î­Î»Î¿Ï…
mae_poly = mean_absolute_error(scaledTestOutput, predictedOutputspoly)
rmse_poly = np.sqrt(mean_squared_error(scaledTestOutput, predictedOutputspoly))
max_poly = max_error(scaledTestOutput, predictedOutputspoly)

#Î•ÎºÏ„ÏÏ€Ï‰ÏƒÎ· Ï„Ï‰Î½ Ï„Î¹Î¼ÏÎ½.
print("\nÎ¥Ï€Î¿Î»Î¿Î³Î¹ÏƒÎ¼ÏŒÏ‚ ÎœÎ­ÏƒÎ¿Ï… Î‘Ï€ÏŒÎ»Ï…Ï„Î¿Ï… Î£Ï†Î¬Î»Î¼Î±Ï„Î¿Ï‚ (Mean Absolute Error), Î¡Î¯Î¶Î±Ï‚ ÎœÎ­ÏƒÎ¿Ï… Î¤ÎµÏ„ÏÎ±Î³ÏÎ½Î¿Ï… Î£Ï†Î¬Î»Î¼Î±Ï„Î¿Ï‚ (Root Mean Square Error) ÎºÎ±Î¹ ÎœÎµÎ³Î¯ÏƒÏ„Î¿Ï… Î£Ï†Î¬Î»Î¼Î±Ï„Î¿Ï‚ (Maximum Error) Ï„Ï‰Î½ Î±ÎºÎ¿Î»Î¿ÏÎ¸Ï‰Î½ ÏƒÏ…Î½Î´Ï…Î±ÏƒÎ¼ÏÎ½: \n")
print("a) Î ÏÎ±Î³Î¼Î±Ï„Î¹ÎºÎ­Ï‚ Î¤Î¹Î¼Î­Ï‚ - Î ÏÎ¿Î²Î»ÎµÏ†Î¸ÎµÎ¯ÏƒÎµÏ‚ Î¤Î¹Î¼Î­Ï‚ Ï„Î¿Ï… Î¼Î¿Î½Ï„Î­Î»Î¿Ï… kNN")
print("   Mean absolute error is: {:.2f}".format(mae_knn))
print("   Root mean squared error is: {:.2f}".format(rmse_knn))
print("   Maximum error is: {:.2f}\n".format(max_knn))

print("b) Î ÏÎ±Î³Î¼Î±Ï„Î¹ÎºÎ­Ï‚ Î¤Î¹Î¼Î­Ï‚ - Î ÏÎ¿Î²Î»ÎµÏ†Î¸ÎµÎ¯ÏƒÎµÏ‚ Î¤Î¹Î¼Î­Ï‚ Ï„Î¿Ï… Î¼Î¿Î½Ï„Î­Î»Î¿Ï… SVM")
print("   Mean absolute error is: {:.2f}".format(mae_svm))
print("   Root mean squared error is: {:.2f}".format(rmse_svm))
print("   Maximum error is: {:.2f}\n".format(max_svm))

print("c) Î ÏÎ±Î³Î¼Î±Ï„Î¹ÎºÎ­Ï‚ Î¤Î¹Î¼Î­Ï‚ - Î ÏÎ¿Î²Î»ÎµÏ†Î¸ÎµÎ¯ÏƒÎµÏ‚ Î¤Î¹Î¼Î­Ï‚ Ï„Î¿Ï… Î Î¿Î»Ï…Ï‰Î½Ï…Î¼Î¹ÎºÎ¿Ï Î¼Î¿Î½Ï„Î­Î»Î¿Ï… ")
print("   Mean absolute error is: {:.2f}".format(mae_poly))
print("   Root mean squared error is: {:.2f}".format(rmse_poly))
print("   Maximum error is: {:.2f}".format(max_poly))

#Î‘Î¾Î¹Î¿Î»ÏŒÎ³Î·ÏƒÎ· Ï„Î·Ï‚ Î±Ï€ÏŒÎ´Î¿ÏƒÎ·Ï‚ Ï„Ï‰Î½ regressors.
print("\nÎ£ÏÎ¼Ï†Ï‰Î½Î± Î¼Îµ Ï„Î± Mean Absolute Error ÎºÎ±Î¹ Root Mean Squared Error ÎµÎ¯Î½Î±Î¹ ÎµÎ¼Ï†Î±Î½Î­Ï‚ ÏŒÏ„Î¹ Ï„Î¿ Î Î¿Î»Ï…Ï‰Î½Ï…Î¼Î¹ÎºÏŒ Î¼Î¿Î½Ï„Î­Î»Î¿ \n\
ÎµÎ¯Î½Î±Î¹ Ï„Î¿ ÎºÎ±Î»ÏÏ„ÎµÏÎ¿ Î±Ï€Î¿ Ï„Î± Ï„ÏÎ¯Î±. ÎˆÏ‡ÎµÎ¹ Ï„Î¹Ï‚ Ï€Î¹Î¿ Ï‡Î±Î¼Î·Î»Î­Ï‚ Î±Ï€Î¿ÎºÎ»Î¯ÏƒÎµÎ¹Ï‚ ÏƒÎµ ÏƒÏ‡Î­ÏƒÎ· Î¼Îµ Ï„Î± Ï…Ï€ÏŒÎ»Î¿Î¹Ï€Î± ÎµÎºÏ€Î±Î¹Î´ÎµÏ…Î¼Î­Î½Î± Î¼Î¿Î½Ï„Î­Î»Î±,\n\
ÎµÎ½Ï ÏƒÏ„Î· Î´ÎµÏÏ„ÎµÏÎ· Î¸Î­ÏƒÎ· Î±ÎºÎ¿Î»Î¿Ï…Î¸ÎµÎ¯ Ï„Î¿ Î¼Î¿Î½Ï„Î­Î»Î¿ kNN Î¼Îµ Î»Î¯Î³Î¿ Î¼ÎµÎ³Î±Î»ÏÏ„ÎµÏÎµÏ‚ Î±Ï€Î¿ÎºÎ»Î¯ÏƒÎµÎ¹Ï‚. Î‘Î¾Î¹Î¿ÏƒÎ·Î¼ÎµÎ¯Ï‰Ï„Î· ÎµÎ¯Î½Î±Î¹ Î· Î´Î¹Î±Ï†Î¿ÏÎ¬ Ï„Î¿Ï… \n\
SVM Î¼Î¿Î½Ï„Î­Î»Î¿Ï… Ï„Î¿ Î¿Ï€Î¿Î¯Î¿, ÎµÎ½Ï Î­Î´ÎµÎ¹Î¾Îµ Î²ÎµÎ»Ï„Î¹Ï‰Î¼Î­Î½Î· Î±Ï€ÏŒÎ´Î¿ÏƒÎ· Î¼Îµ ÎºÎ±Î½Î¿Î½Î¹ÎºÎ¿Ï€Î¿Î¹Î·Î¼Î­Î½Î± Î´ÎµÎ´Î¿Î¼Î­Î½Î±, Ï€Î±ÏÎ±Î¼Î­Î½ÎµÎ¹ ÎºÎ±Ï„Î¬ Ï€Î¿Î»Ï \n\
Ï‡ÎµÎ¹ÏÏŒÏ„ÎµÏÎ¿ ÏƒÏ„Î¹Ï‚ Ï€ÏÎ¿Î²Î»Î­ÏˆÎµÎ¹Ï‚ Î±Ï€Î¿ Ï„Î± Î¬Î»Î»Î±.")